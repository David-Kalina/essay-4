export const initialText = `"Listen, chump, I've been waiting for a refill for the last 15 minutes." The robot stared at the man intently before heading to the soda dispensers. Miraculously, with a series of calculated steps, the robot filled a cup with soda and proceeded to return back to the angry customer. "About time you hunk of junk." said the angry man. "Honey, it's its first day on the job, have a heart." said the man's wife. As the angry customer calmed down, the robot performed the dangerous procedure of setting the refilled glass onto the table. It started off looking pretty convincing until the robot lapsed in judgment and spilled the drink all over the table, soaking the entire table. "That's it; I'm speaking to your manager." The robot again stared at the man intently, but after a few seconds, it displayed the bill's total and the suggested tip amount on the terminal embedded into its torso. "Unbelievable, you can't even put a glass of soda on the table but can easily tell me how much I owe you?" This time, the angry customer's voice resonated throughout the restaurant prompting the manager to diffuse the situation. The manager approached the table, suggesting that he'd already known the commotion. After agreeing to allow the couple to leave the restaurant without paying, he turned to the robot and said, "Sorry bud, it's just not working out." and fired it.

Now, that was a fictional dramatization of when robot waiters in China were fired for failing to perform even the simplest of tasks, like carrying soup from point A to point B ("Robot waiters fired..."). Despite the threat of automation, it turns out that waiting tables, among many other tasks that humans can solve intuitively, are much more complicated than current robotics and artificial intelligence can handle. Yet this begs the question, will there ever a be a time when computers will be able to outperform humans at most tasks? If so, will the advent of AI technology lead to the replacement of human beings, or will it usher in a new age of convenience beyond comprehension?

So what are some things that AI can do? Well, typically, AI is grouped into two categories. The one that doesn't strike an existential fear into your soul is known as "Narrow AI." Automatically handling spam emails, processing images, and even self-driving cars are all examples of Narrow AI. They all perform tasks that humans perform daily efficiently but are utterly useless outside their respective domains. You never have to worry that the AI that filters promotional emails for the clothing brand you've never heard of will someday wipe out the human race. Like a well-trained circus animal, the spam-filtering AI will continue to perform its one-trick wonder that humans can appreciate. However, another type of AI is so terrifying that it makes you fearfully reconsider the dramatized interpretation of advanced AI in movies like "I, Robot" and "War Games" as possibilities in the future known as General AI. In those movies, AI can do everything that humans can. From launching nuclear warheads to taking over robots that maintain law and order. But with narrow AI only possessing the capabilities to do particular tasks, what enables the jump for a computer to approach - or even exceed - human levels of intelligence?

Recursive self-improvement. The idea is that an AI system can be used to generate a better AI system. This process would theoretically continue until an AI system far more intelligent than humans is created. The main concern with this is that the AI will execute tasks in a way that is unexpected and could potentially destroy humans. For example, let's say an AI is trained to be the best Pac-Man player ever. The AI experts behind the Pac-Man master AI want the AI to get a ridiculously high score in the game. Instead of being "the best" Pac-Man player ever, maybe the AI hacks the game and gives itself a super high score, despite not actually playing it. These ethical concerns need to be taken seriously with the possibility of AI becoming more general. Elon musk posed a hypothetical in which humans ask AI to solve world hunger. The AI responds by wiping out all humans. But, that doesn't mean that humans should halt developments in AI; there are still skeptics that don't believe AI is headed towards an inevitable takeover of the human race (Zacarina).

Most of the buzz surrounding the superintelligence scare stems from Nick Bostrom, a philosopher. His famous book, Super Intelligence, Paths, Dangers, Strategies, has influenced the minds of Elon Musk and Stephen Hawking. They are convinced that the threat of Digital Superintelligence is near and perilous. However, not all great thinkers that are familiar with AI are in agreement. One of the comments, "We're competing with millions of years' evolution of the human brain. We can write single-purpose programs that can compete with humans, and sometimes excel, but the world is not neatly compartmentalized into single-problem questions." was made in response to a survey conducted by Bostrom asking participants when they believed an AI would reach "super human" levels (Etzioni). 

So, in the end, like most things, it's complicated, and nobody knows the future. Based on both sides of the AI "friend or foe." argument, the best we can do is be conscious of the power of AI and always ask in what ways we can safeguard against a dangerous future with it. We still don't live in the future where there are reliable self-driving cars, Siri and Google Assistant still are hit-or-miss, and as explored earlier, Robot waiters just can't cut it. So the next time you go to a restaurant, tip your waiter or waitress a little extra; they're doing something that the most sophisticated advancements in robotics and artificial intelligence can't do. 








`
